
<!DOCTYPE html>
<html>
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>How to Make KafkaProducer Reliable</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.0/css/bootstrap.min.css" integrity="sha384-SI27wrMjH3ZZ89r4o+fGIJtnzkAnFs3E4qz9DIYioCQ5l9Rd/7UAa8DHcaL8jkWt" crossorigin="anonymous">
    <style>
      pre { background: #f5f5f5; border: 1px solid #ddd; border-radius: 4px; padding: 0.6em 1em; }
      h1,h2 { margin-top: 1em; }
      div.navbar { padding: 8px 0; }
      div.toc { float: right; }
    </style>
  </head>
  <body>
    <div class="container">
      <h1 id="how-to-make-kafkaproducer-reliable"><a class="toclink" href="#how-to-make-kafkaproducer-reliable">How to Make KafkaProducer Reliable</a></h1>
<p>While using message dispatching systems, we always suffer from message lost, duplication and disordering.</p>
<p>Since the application (using the <code>KafkaProducer</code>) might crash/restart, we might consider using certain mechanism to achieve <code>At most once</code>/<code>At least once</code>, and <code>Ordering</code>, -- such as locally persisting the messages until successful delivery, using embedded sequence number to de-duplicate, or responding data-source to acknowledgement the delivery result, etc. These are common topics, which are not quite specific to Kafka. </p>
<p>Here we'd focus on <code>KafkaProducer</code>, together with the <code>idempotence</code> feature. Let's see, in which cases problems might happen, how to avoid them, and what's the best practise,-- to achieve <code>No Message Lost</code>, <code>Exactly Once</code> and <code>Ordering</code>.</p>
<h2 id="about-no-message-lost"><a class="toclink" href="#about-no-message-lost">About <code>No Message Lost</code></a></h2>
<h3 id="when-might-a-message-actually-be-lost"><a class="toclink" href="#when-might-a-message-actually-be-lost">When might a message actually be lost</a></h3>
<ul>
<li>The producer gets a successful delivery response after sending the message, but the <code>partition leader</code> failed to sync it to other <code>replicas</code>.</li>
</ul>
<h3 id="how-could-a-message-be-lost-even-with-successful-delivery"><a class="toclink" href="#how-could-a-message-be-lost-even-with-successful-delivery">How could a message be lost even with successful delivery</a></h3>
<ul>
<li>
<p>First, the <code>partition leader</code> doesn't sync-up the latest message to enough <code>in-sync replicas</code> before responding with the <code>ack</code></p>
<ul>
<li>
<p>The <code>partition leader</code> just don't need to wait for other <code>replica</code>s response</p>
<ul>
<li>E.g, the producer is configured with <code>acks=1</code></li>
</ul>
</li>
<li>
<p>No available <code>in-sync replica</code> to wait for the response</p>
<ul>
<li>E.g, all other replicas are not in-sync</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Then, the <code>partition leader</code> crashes, and one <code>in-sync replica</code> becomes new <code>partition leader</code></p>
<ul>
<li>The new <code>partition leader</code> has no acknowledgement with the latest messages. Later, while new messages arrive, it would use conflicting record offsets (same with those records which the <code>partition leader</code> knows only). Then, even if the previous <code>partition leader</code> comes up again, these records have no chance to be recovered (just internally overwritten to be consistent with other replicas).</li>
</ul>
</li>
</ul>
<h3 id="how-to-make-sure-no-message-lost"><a class="toclink" href="#how-to-make-sure-no-message-lost">How to make sure <code>No Message Lost</code></a></h3>
<ul>
<li>
<p>Make sure the leader would wait for responses from all in-sync replicas before the response</p>
<ul>
<li>Configuration <code>acks=all</code> is a MUST for producer</li>
</ul>
</li>
<li>
<p>Ensure enough <code>In-Sync partition replicas</code></p>
<ul>
<li>
<p>Configuration <code>min.insync.replicas &gt;= 2</code> is a MUST for brokers</p>
<ul>
<li>
<p>Take <code>min.insync.replicas = 2</code> for example, it means,</p>
<ol>
<li>
<p>At most <code>replication.factor - min.insync.replicas</code> replicas are out-of-sync, -- the producer would still be able to send messages, otherwise, it could fail with 'no enough replica' error, and keeps retrying.</p>
</li>
<li>
<p>Occasionally no more than <code>min.insync.replicas</code> in-sync-replica failures. -- otherwise, messages might be missed. In this case, if just one in-sync replica crashes after sending back the ack to the producer, the message would not be lost; if two failed, it would! Since the new leader might be a replica which was not in-sync previously, and has no acknowledgement with these latest messages.</p>
</li>
</ol>
</li>
</ul>
</li>
<li>
<p>Please refer to <a href="KafkaBrokerConfiguration.md">Kafka Broker Configuration</a> for more details.</p>
</li>
<li>
<p>Then, what would happen if replicas fail</p>
<ol>
<li>
<p>Fails to send (<code>not enough in-sync replica failure</code>), -- while number of <code>in-sync replicas</code> could not meet <code>min.insync.replication</code> </p>
</li>
<li>
<p>Lost messages (after sending messages), -- with no <code>in-sync replica</code> survived from multi-failures</p>
</li>
<li>
<p>No message lost (while with all <code>in-sync replicas</code> acknowledged, and at least one <code>in-sync replica</code> available)</p>
</li>
</ol>
</li>
</ul>
</li>
</ul>
<h2 id="about-exactly-once"><a class="toclink" href="#about-exactly-once">About <code>Exactly Once</code></a></h2>
<h3 id="how-duplications-happen"><a class="toclink" href="#how-duplications-happen">How duplications happen</a></h3>
<ul>
<li>After brokers successfully persisted a message, it sent the <code>ack</code> to the producer. But for some abnormal reasons (such as network failure, etc), the producer might fail to receive the <code>ack</code>. The <code>librdkafka</code>'s internal queue would retry, thus another (duplicated) message would be persisted by brokers.</li>
</ul>
<h3 id="how-to-guarantee-exactly-once"><a class="toclink" href="#how-to-guarantee-exactly-once">How to guarantee <code>Exactly Once</code></a></h3>
<ul>
<li>The <code>enable.idempotence</code> configuration is RECOMMENDED.</li>
</ul>
<h2 id="about-ordering"><a class="toclink" href="#about-ordering">About <code>Ordering</code></a></h2>
<h3 id="no-ordering-between-partitions"><a class="toclink" href="#no-ordering-between-partitions">No ordering between partitions</a></h3>
<ul>
<li>
<p>Make sure these <code>ProducerRecord</code>s be with the same partition</p>
<ul>
<li>
<p>Explicitly assigned with the same <code>topic-partition</code></p>
</li>
<li>
<p>Use the same <code>key</code> for these records</p>
</li>
</ul>
</li>
</ul>
<h3 id="how-disordering-happens-within-one-partition"><a class="toclink" href="#how-disordering-happens-within-one-partition">How disordering happens within one partition</a></h3>
<ul>
<li>
<p>The <code>librdkafka</code> uses internal partition queues, and once a message fails to be sent successfully(e.g, brokers are down), it would be put back on the queue and retries again while <code>retry.backoff.ms</code> expires. However, before that (retry with the failed message), the brokers might recover and the messages behind (if with configuration <code>max.in.flight &gt; 1</code>) happened to be sent successfully. In this case (with configuration <code>max.in.flight &gt; 1</code> and <code>retries &gt; 0</code>), disordering could happen, and the user would not even be aware of it.</p>
</li>
<li>
<p>Furthermore, while the last retry still failed, delivery callback would eventually be triggered. The user has to determine what to do for that (might want to re-send the message, etc). But there might be a case, -- some later messages had already been saved successfully by the server, thus no way to revert the disordering.</p>
</li>
</ul>
<h2 id="more-about-idempotent-producer"><a class="toclink" href="#more-about-idempotent-producer">More About <code>Idempotent producer</code></a></h2>
<p>Please refer to the document from librdkafka, <a href="https://github.com/edenhill/librdkafka/blob/master/INTRODUCTION.md#idempotent-producer">Idempotent Producer</a> for more details.</p>
<h3 id="extra-fields-to-maintain-the-message-sequence"><a class="toclink" href="#extra-fields-to-maintain-the-message-sequence">Extra fields to maintain the message sequence</a></h3>
<p>The <code>librdkafka</code> maintains the original produce() ordering per-partition for all messages produced, using an internal per-partition 64-bit counter called the <code>msgid</code> which starts at 1. This <code>msgid</code> allows messages to be re-inserted in the partition message queue in the original order in the case of retries.</p>
<p>The Idempotent Producer functionality in the Kafka protocol also has a per-message <code>sequence number</code>, which is a signed 32-bit wrapping counter that is reset each time the <code>Producer's ID (PID)</code> or <code>Epoch</code> changes.</p>
<p>The <code>msgid</code> is used, (along with a base <code>msgid</code> value stored at the time the <code>PID/Epoch</code> was bumped), to calculate the Kafka protocol's message <code>sequence number</code>.</p>
<h3 id="configuration-conflicts"><a class="toclink" href="#configuration-conflicts">Configuration conflicts</a></h3>
<ul>
<li>
<p>Since the following configuration properties are adjusted automatically (if not modified by the user). Producer instantiation will fail if user-supplied configuration is incompatible.</p>
<ul>
<li>
<p><code>acks = all</code></p>
</li>
<li>
<p><code>max.in.flight (i.e,</code>max.in.flight.requests.per.connection<code>) = 5</code></p>
</li>
<li>
<p><code>retries = INT32_MAX</code></p>
</li>
</ul>
</li>
</ul>
<h3 id="error-handling"><a class="toclink" href="#error-handling">Error handling</a></h3>
<ul>
<li>
<p>Exception thrown during <code>send</code></p>
<ul>
<li>For these errors which could be detected locally (and could not be recovered with retrying), an exception would be thrown. E.g, invalid message, as RD_KAFKA_RESP_ERR_INVALID_MSG_SIZE (conflicting with local configuration <code>message.max.bytes</code>).</li>
</ul>
</li>
<li>
<p>Permanent errors (respond from brokers)</p>
<ul>
<li>
<p>Typical errors are:</p>
<ul>
<li>
<p>Invalid message: RD_KAFKA_RESP_ERR_CORRUPT_MESSAGE, RD_KAFKA_RESP_ERR_MSG_SIZE_TOO_LARGE, RD_KAFKA_RESP_ERR_INVALID_REQUIRED_ACKS, RD_KAFKA_RESP_ERR_UNSUPPORTED_FOR_MESSAGE_FORMAT, RD_KAFKA_RESP_ERR_RECORD_LIST_TOO_LARGE.</p>
</li>
<li>
<p>Topic/Partition not exist: ERR_UNKNOWN_TOPIC_OR_PART, -- automatic topic creation is disabled on the broker or the application is specifying a partition that does not exist.</p>
</li>
<li>
<p>Authorization failure: ERR_TOPIC_AUTHORIZATION_FAILED, ERR_CLUSTER_AUTHORIZATION_FAILED</p>
</li>
</ul>
</li>
<li>
<p>Normally, <code>Permanent error</code> means careless design, or wrong configuration, which should be avoided from the very beginning.</p>
</li>
<li>
<p>Unless with <code>enable.gapless.guarantee</code>(EXPERIMENTAL) configured, producer would keep going with the following messages; otherwise, it would purge all messages in-flight/in-queue (with RD_KAFKA_RESP_ERR__PURGE_INFLIGHT/RD_KAFKA_RESP_ERR__PURGE_QUEUE). </p>
</li>
</ul>
</li>
<li>
<p>Temporary errors</p>
<ul>
<li>Apart from those <code>permanent errors</code>, most of the left are temporary errors, which will be retried (if retry count permits); and while <code>message.timeout</code> expired, message delivery callback would be triggered with <code>RD_KAFKA_RESP_ERR__TIEMD_OUT</code>.</li>
</ul>
</li>
<li>
<p>Be careful with the <code>RD_KAFKA_RESP_ERR__TIEMD_OUT</code> failure</p>
<ul>
<li>
<p>There's some corner cases, such as a message that has been persisted by brokers but <code>KafkaProducer</code> failed to get the response. If <code>message.timeout.ms</code> has not expired, the producer could retry and eventually get the response. Otherwise, (i.e, <code>message.timeout.ms</code> expired before the producer receives the successful <code>ack</code>), it would be considered as a delivery failure by the producer (while the brokers wouldn't). Users might re-transmit the message thus causing duplications.</p>
</li>
<li>
<p>To avoid this tricky situation, a longer <code>message.timeout.ms</code> is RECOMMENDED, to make sure there's enough time for transmission retries / on-flight responses.</p>
</li>
</ul>
</li>
</ul>
<h3 id="performance-impact"><a class="toclink" href="#performance-impact">Performance impact</a></h3>
<ul>
<li>The main impact comes from <code>max.in.flight=5</code> limitation. Currently, <code>max.in.flight</code> means <code>max.in.flight.per.connection</code>, -- that's 5 message batches (with size of ~1MB at the most) in flight (not get the <code>ack</code> response yet) at the most, towards per broker. Within low-latency networks, it would not be a problem; while in other cases, it might be! Good news is, there might be a plan (in <code>librdkafka</code>) to improve that <code>per.connection</code> limit to <code>per.partition</code>, thus boost the performance a lot.</li>
</ul>
<h2 id="the-best-practice-for-kafkaproducer"><a class="toclink" href="#the-best-practice-for-kafkaproducer">The best practice for <code>KafkaProducer</code></a></h2>
<ul>
<li>
<p>Enable <code>enable.idempotence</code> configuration</p>
</li>
<li>
<p>Use a long <code>message.timeout.ms</code>, which would let <code>librdkafka</code> keep retrying, before triggering the delivery failure callback.</p>
</li>
</ul>
<h2 id="some-examples"><a class="toclink" href="#some-examples">Some examples</a></h2>
<h3 id="kafkaproducer-demo"><a class="toclink" href="#kafkaproducer-demo"><code>KafkaProducer</code> demo</a></h3>
<div class="codehilite"><pre><span></span>    <span class="n">std</span><span class="o">::</span><span class="n">atomic</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">running</span> <span class="o">=</span> <span class="nb">true</span><span class="p">;</span>



    <span class="n">KafkaProducer</span> <span class="nf">producer</span><span class="p">(</span>

        <span class="n">Properties</span><span class="p">({</span>

            <span class="p">{</span> <span class="n">ProducerConfig</span><span class="o">::</span><span class="n">BOOTSTRAP_SERVERS</span><span class="p">,</span>  <span class="s">&quot;192.168.0.1:9092,192.168.0.2:9092,192.168.0.3:9092&quot;</span> <span class="p">},</span>

            <span class="p">{</span> <span class="n">ProducerConfig</span><span class="o">::</span><span class="n">ENABLE_IDEMPOTENCE</span><span class="p">,</span> <span class="s">&quot;true&quot;</span> <span class="p">},</span>

            <span class="p">{</span> <span class="n">ProducerConfig</span><span class="o">::</span><span class="n">MESSAGE_TIMEOUT_MS</span><span class="p">,</span> <span class="s">&quot;86400000&quot;</span><span class="p">}</span>  <span class="c1">// as long as 1 day</span>

        <span class="p">})</span>

    <span class="p">);</span>



    <span class="k">while</span> <span class="p">(</span><span class="n">running</span><span class="p">)</span> <span class="p">{</span>

        <span class="k">auto</span> <span class="n">msg</span> <span class="o">=</span> <span class="n">fetchMsgFromUpstream</span><span class="p">();</span>

        <span class="k">auto</span> <span class="n">record</span> <span class="o">=</span> <span class="n">ProducerRecord</span><span class="p">(</span><span class="n">topic</span><span class="p">,</span> <span class="n">msg</span><span class="p">.</span><span class="n">key</span><span class="p">,</span> <span class="n">msg</span><span class="p">.</span><span class="n">value</span><span class="p">,</span> <span class="n">msg</span><span class="p">.</span><span class="n">id</span><span class="p">);</span>

        <span class="n">producer</span><span class="p">.</span><span class="n">send</span><span class="p">(</span><span class="n">record</span><span class="p">,</span>

                      <span class="c1">// Ack callback</span>

                      <span class="p">[</span><span class="o">&amp;</span><span class="n">msg</span><span class="p">](</span><span class="k">const</span> <span class="n">Producer</span><span class="o">::</span><span class="n">RecordMetadata</span><span class="o">&amp;</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">error_code</span> <span class="n">ec</span><span class="p">)</span> <span class="p">{</span>

                           <span class="c1">// the message could be identified by `metadata.recordId()`</span>

                           <span class="k">auto</span> <span class="n">recordId</span> <span class="o">=</span> <span class="n">metadata</span><span class="p">.</span><span class="n">recordId</span><span class="p">();</span>

                           <span class="k">if</span> <span class="p">(</span><span class="n">ec</span><span class="p">)</span>  <span class="p">{</span>

                               <span class="n">std</span><span class="o">::</span><span class="n">cerr</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;Cannot send out message with recordId: &quot;</span> <span class="o">&lt;&lt;</span> <span class="n">recordId</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;, error:&quot;</span> <span class="o">&lt;&lt;</span> <span class="n">ec</span><span class="p">.</span><span class="n">message</span><span class="p">()</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>

                           <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>

                               <span class="n">commitMsgToUpstream</span><span class="p">(</span><span class="n">recordId</span><span class="p">);</span>

                           <span class="p">}</span>

                       <span class="p">});</span>

    <span class="p">}</span>



    <span class="n">producer</span><span class="p">.</span><span class="n">close</span><span class="p">();</span>
</pre></div>

<ul>
<li>With a long <code>message.timeout.ms</code>, we're not likely to catch an error with delivery callback, --it would retry for temporary errors anyway. But be aware with permanent errors, it might be caused by careless design.</li>
</ul>
      <hr/>
      <footer class="text-center text-muted">
        Generated: 2022. 03. 15
      </footer>
      <hr/>
    </div>
  </body>
</html>